syntax = "proto3";

package train_2048.inference.v1;

// High-level contract for 2048 inference. Versioned under `v1` for evolvability.
// This variant returns per-head probability distributions over bins and avoids
// leaking backend/dtype/padding details into the wire format.

// A single inference item: caller-provided id and a compact board encoding.
message Item {
  // Stable, caller-supplied identifier for routing results.
  uint64 id = 1;
  // Board exponents in row-major order. Exactly 16 bytes for a 4x4 board.
  // 0 = empty, 1 = 2, 2 = 4, ...
  bytes board = 2; // len == 16
}

// Request a batched inference over one or more boards.
message InferRequest {
  // Optional logical identifier of the model or init to route against.
  string model_id = 1;

  // Batch of inputs to evaluate.
  repeated Item items = 2;

  // Optional batch identifier for telemetry/correlation.
  uint64 batch_id = 3;

  // If true, include a pooled embedding for each item in the response.
  // Embedding is returned as raw bytes; see InferResponse.embed_dtype.
  bool return_embedding = 4;

  // If true, the server MAY skip returning full per-head distributions and
  // instead emit argmax-only decisions (see InferResponse.argmax_heads /
  // argmax_p1). Clients should fall back to full distributions when unset.
  bool argmax_only = 5;

  // Control which outputs are returned. The default is backward-compatible:
  // policy heads are always returned, and value outputs are included only when
  // a value head exists in the checkpoint.
  OutputMode output_mode = 6;

  // Optional: request value per-bin probabilities. By default, value probs are
  // sent when policy is requested; value-only calls omit the distribution to
  // keep responses small unless this is explicitly set.
  bool include_value_probs = 7;

  enum OutputMode {
    OUTPUT_MODE_UNSPECIFIED = 0; // Default/autodetect: policy always, value if available.
    OUTPUT_MODE_POLICY_ONLY = 1; // Force policy only even if value head exists.
    OUTPUT_MODE_VALUE_ONLY = 2;  // Require value head; emit value only (error if missing).
    OUTPUT_MODE_POLICY_AND_VALUE = 3; // Require value head; emit both policy and value.
  }
}

// A single head's distribution as probabilities over bins.
message HeadProbs {
  // Probabilities (sum ~ 1.0). len == n_bins, shared across heads.
  repeated float probs = 1;
}

// Per-board output: per-head probability distributions.
// Heads are ordered [Up, Down, Left, Right] to match dataset order.
message Output {
  // Shape conceptually: (4, n_bins)
  repeated HeadProbs heads = 1;

  // Optional pooled embedding for this item, encoded per InferResponse.embed_dtype.
  // When empty, no embedding was requested or returned.
  bytes embedding = 2;

  // Optional value head output for the current board (not the next move).
  ValueOutput value = 3;
}

// Value head output for the current board state.
message ValueOutput {
  // Expected value after applying any known inverse transform (best effort).
  optional float value = 1;
  // Expected value in the model's output space before inverse transform.
  optional float value_xform = 2;
  // Probability distribution over value bins (categorical/two-hot heads).
  repeated float probs = 3;
}

// Metadata describing model/tokenizer semantics for policy heads.
message PolicyMetadata {
  // Logical head type (e.g., "binned_ev", "action_policy").
  string head_type = 1;
  // Number of bins emitted per head (shared across heads).
  uint32 bin_count = 2;
  // Optional tokenizer identifier (e.g., "macroxue_ev_advantage_v2").
  string tokenizer_type = 3;
  // Optional human-readable labels for each bin (ILLEGAL, FAILURE, ... WINNER).
  repeated string vocab_labels = 4;
}

message ModelMetadata {
  // Policy/tokenizer metadata; future fields may cover embeddings/value heads.
  PolicyMetadata policy = 1;
  // Value head metadata (objective, support, transform hints).
  ValueMetadata value = 2;
}

// Metadata describing value head semantics.
message ValueMetadata {
  // Objective type (e.g., "mse", "cross_entropy"). Empty when no value head exists.
  string objective = 1;
  // Number of bins emitted by a categorical value head.
  uint32 vocab_size = 2;
  // Optional label for the value vocab/bins.
  string vocab_type = 3;
  // Optional support definition for categorical heads.
  optional float support_min = 4;
  optional float support_max = 5;
  // Optional MuZero transform epsilon and application flag.
  optional float transform_epsilon = 6;
  optional bool apply_transform = 7;
  // Optional training target used for the value head (e.g., return_scaled).
  string target = 8;
}

// Batched inference response.
message InferResponse {
  // Echoed from request if provided.
  uint64 batch_id = 1;

  // Item identifiers in the same order as outputs.
  repeated uint64 item_ids = 2;

  // One output per input board (same order as item_ids).
  repeated Output outputs = 3;

  // Server-measured latency in milliseconds for the batch, if available.
  uint64 latency_ms = 4;

  // Embedding metadata (present when return_embedding was true).
  // All embeddings in this response share the same shape and dtype.
  uint32 embed_dim = 5;
  enum EmbedDType {
    EMBED_DTYPE_UNSPECIFIED = 0;
    FP32 = 1;  // float32 bytes, little-endian
    BF16 = 2;  // bfloat16 16-bit words, little-endian
  }
  EmbedDType embed_dtype = 6;

  // Optional: when embeddings are requested, servers MAY return a single
  // concatenated buffer containing all embeddings in batch order to avoid
  // per-item serialization overhead. The buffer layout is:
  //   [item0 (embed_dim * sizeof(dtype))][item1][...][itemB-1]
  // Clients should prefer this field when present; fall back to per-item
  // Output.embedding otherwise. The number of items is `len(item_ids)`.
  bytes embeddings_concat = 7;

  // When InferRequest.argmax_only=true, servers MAY populate these fields
  // with the argmax head index (0=Up,1=Down,2=Left,3=Right) and its
  // corresponding probability mass in the final bin (p1). Length matches
  // len(item_ids). When empty, fall back to `outputs`.
  repeated uint32 argmax_heads = 8;
  repeated float argmax_p1 = 9;

  // Optional metadata describing model/tokenizer semantics.
  ModelMetadata model_metadata = 10;
}

// Request server capabilities and model metadata without running inference.
message DescribeRequest {}

message DescribeResponse {
  // Advertised metadata for the loaded model/init.
  ModelMetadata model_metadata = 1;
  // True when the server exposes a policy head.
  bool has_policy_head = 2;
  // True when the server exposes a value head and can return value outputs.
  bool has_value_head = 3;
}

service Inference {
  // Compute per-head probability distributions over bins for each input.
  rpc Infer (InferRequest) returns (InferResponse);
  // Advertise server capabilities (policy/value/tokenizer metadata).
  rpc Describe (DescribeRequest) returns (DescribeResponse);
}
