num_seeds = 256
max_retries = 1
max_concurrent_games = 256

[sampling]
# Softmax sampling over a single policy head (hard targets).
# Temperature applies to per-move probabilities (UDLR) returned by the server.
strategy = "Softmax"
temperature = 0.30

# Optional: gates for when to apply non-argmax sampling.
# Outside the window, fall back to argmax.
# start_gate = 0   # default: 0 (enable from the first move)
# stop_gate = 64   # default: unset (never stop)

[orchestrator.connection]
# One of uds_path or tcp_addr must be set for the Python server.
uds_path = "/tmp/2048_infer.sock"
# tcp_addr = "http://127.0.0.1:50051"

[orchestrator]
# Single policy head is trained in UDLR (Up, Down, Left, Right) order.
head_order = "UDLR"
# For hard-move models, keep argmax_only=false to enable temperature sampling.
argmax_only = false

[orchestrator.batch]
# Time-based flush interval for micro-batches (microseconds)
flush_us = 500
target_batch = 128
max_batch = 256
inflight_batches = 2
per_game_inflight = 8
queue_cap = 8192

# Optional: client-side batching metrics (JSONL)
# metrics_file = "profiles/client-metrics.jsonl"
# metrics_interval_s = 5.0

# Optional: per-game results (JSONL)
# [orchestrator.report]
# results_file = "runs/results.jsonl"

