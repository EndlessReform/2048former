init_dir = "inits/v2/10m_ablations/narrow_n3_5_binned"
checkpoint_dir = "checkpoints"
seed = 42

[wandb]
enabled = true
project = "train-2048-bin-v2"
entity = ""
run_name = ""
tags = ["v2", "macroxue-binned", "narrow_n3_5"]
mode = "online"                                 # online | offline | disabled
report_every = 50                               # log to W&B every N steps (>=1)

[target]
mode = "macroxue_tokens" # single 4-way policy head

[hyperparameters]
learning_rate = 5e-4
# Clip global gradient norm each step (None to disable)
grad_clip_norm = 0.5

[hyperparameters.lr_schedule]
name = "cosine"
warmup_steps = 3000
min_lr_ratio = 0.1

[hyperparameters.optimizer]
name = "adamw"      # adamw | muon
weight_decay = 0.01
beta1 = 0.90
beta2 = 0.99
eps = 1e-8

[batch]
batch_size = 1024
micro_batch_size = 1024

[batch.adaptive]
enabled = false
# double_at_lr_ratio = 0.5
# quadruple_at_lr_ratio = 0.25

[dropout]
dropout_prob = 0.05
attention_dropout_prob = 0.0

[dataset]
dataset_dir = "datasets/d6_3b_v0"
tokenizer_path = "out/macroxue_v2/tokenizer.json"
mmap_mode = true
num_epochs = 1
shard_locality = true

# Keep validation small and frequent for sanity
val_run_pct = 0.005
val_split_seed = 42
val_num_steps = 200
val_every = 5_000

[checkpoint]
every_epochs = 1
save_pt_every_steps = 100_000
save_best_every_steps = 50_000
best_min_delta = 0.002
