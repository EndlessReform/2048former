# init_dir = "inits/v1_50m_20250830_stable"
init_dir = "inits/v1/10m_32bin"
# init_dir = "inits/v1_50m_20250906_longctxt_base"
checkpoint_dir = "checkpoints"
seed = 0

[wandb]
enabled = true
project = "train-2048-long-ctxt-32bin"
entity = ""
run_name = ""
tags = []
mode = "online"                        # online | offline | disabled
report_every = 50                      # log to W&B every N steps (>=1)

[hyperparameters]
learning_rate = 6e-4
muon_lr = 2e-2

[hyperparameters.lr_schedule]
name = "warmup-stable-decay" # constant | warmup-stable-decay
warmup_steps = 400
# decay_steps = 0
# Alternatively, specify a percentage of total steps for cooldown/decay
cooldown_pct = 0.2 # e.g., last 10% of steps
min_lr_ratio = 0.1

[hyperparameters.optimizer]
name = "adamw"      # adamw | muon
weight_decay = 0.01
beta1 = 0.9
beta2 = 0.98
eps = 1e-8

[batch]
batch_size = 1536
# micro_batch_size = 256

[dropout]
dropout_prob = 0.03
attention_dropout_prob = 0.0

[binning]
# strategy = "edges" | "upper_bounds"
strategy = "edges"
# ensure exact 0 and exact 1 are isolated into their own bins
special_zero_one = true
# Semantic edges for EV discretization (default used if omitted)
# Hybrid: Super-fine near 1.0
edges = [
    0.0,
    # Coarse below 0.9 (10 bins)
    0.1,
    0.3,
    0.5,
    0.6,
    0.7,
    0.8,
    0.85,
    0.88,
    0.90,

    # Everything else in the critical zone (22 bins)
    0.92,
    0.94,
    0.95,
    0.96,
    0.965,
    0.97,
    0.973,
    0.976,
    0.979,
    0.982,
    0.985,
    0.987,
    0.989,
    0.991,
    0.993,
    0.994,
    0.995,
    0.996,
    0.997,
    0.998,
    0.999,
    0.9995,
    1.0,
]

[dataset]
# Root directory containing steps.npy and metadata.db
dataset_dir = "./datasets/ds_v4_full-game"

# Universe selection via SQL (optional)
# run_sql = "SELECT id FROM runs WHERE max_score BETWEEN ? AND ?"
# sql_params = [50_000, 2_000_000]

# Drive by epochs
num_epochs = 3

# Validation: disjoint by runs. Here, use a fixed percentage split.
val_run_pct = 0.02
val_split_seed = 42

val_every = 5_000

[checkpoint]
# Save every epoch (keep all). Epoch count is small.
every_epochs = 1
# Optionally save a best checkpoint every N steps based on validation loss.
# This is a coarse interval to avoid frequent disk writes.
save_best_every_steps = 10000
# Require a small improvement to update the best to reduce churn.
best_min_delta = 0.002
