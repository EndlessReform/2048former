init_dir = "inits/v1_50m_20250830_stable"
checkpoint_dir = "checkpoints"
seed = 0

[wandb]
enabled = true
project = "train-2048-long-ctxt"
entity = ""
run_name = ""
tags = []
mode = "online"                  # online | offline | disabled
report_every = 50                # log to W&B every N steps (>=1)

[hyperparameters]
learning_rate = 2e-5
muon_lr = 2e-2

[hyperparameters.lr_schedule]
name = "warmup-stable-decay" # constant | warmup-stable-decay
warmup_steps = 200
# decay_steps = 0
# Alternatively, specify a percentage of total steps for cooldown/decay
cooldown_pct = 0.1 # e.g., last 10% of steps
min_lr_ratio = 0.1

[hyperparameters.optimizer]
name = "adamw"      # adamw | muon
weight_decay = 0.01
beta1 = 0.9
beta2 = 0.95
eps = 1e-8

[batch]
batch_size = 128
# micro_batch_size = 256

[dropout]
dropout_prob = 0.1
attention_dropout_prob = 0.0

[binning]
# strategy = "edges" | "upper_bounds"
strategy = "edges"
# ensure exact 0 and exact 1 are isolated into their own bins
special_zero_one = true
# Semantic edges for EV discretization (default used if omitted)
edges = [0.0, 0.5, 0.8, 0.9, 0.95, 0.98, 0.99, 0.995, 0.998, 0.999, 1.0]

[dataset]
# Path is resolved relative to the repo root when not absolute
packfile = "./datasets/ds-long-context.a2pack"
# For quick validation, run a fixed number of steps
#num_steps = 100_000
# Or drive by epochs instead (steps takes priority if both set)
num_epochs = 3
