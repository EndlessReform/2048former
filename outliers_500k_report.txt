Loaded attn_norm shape=(4096, 24, 16, 384) dtype=torch.float32 elements=603,979,776 ~2,304.0 MiB
Computing IQR estimate
Computing outlier mask
Filtering by layer-fraction requirement
Summarizing by hidden dimension/layer/token
Summarizing sign distribution
Summarizing first-layer emergence
Summarizing outlier magnitudes
IQR sample 2,000,000 values (seed=0)
                   Activation Outliers (attn_norm)                   
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Metric                             ┃ Value                        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ Input                              │ activations_500k.safetensors │
│ Key                                │ attn_norm                    │
│ Threshold                          │ 6.0000                       │
│ Min layer fraction                 │ 25.00%                       │
│ Tensor shape                       │ (4096, 24, 16, 384)          │
│ Elements > threshold               │ 2,294,752                    │
│ Outlier occurrences                │ 2,096,616                    │
│ Outlier occurrence rate            │ 0.3471%                      │
│ Outlier locations                  │ 131,039                      │
│ Outlier location rate              │ 0.5207%                      │
│ Mean layer-hit fraction (outliers) │ 66.67%                       │
│ Q1 (25%)                           │ -0.4859                      │
│ Median (50%)                       │ -0.0057                      │
│ Q3 (75%)                           │ 0.4754                       │
│ IQR (Q3-Q1)                        │ 0.9612                       │
└────────────────────────────────────┴──────────────────────────────┘
   Outlier Dimensions (attn_norm)   
┏━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┓
┃ Metric                 ┃ Value   ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━┩
│ Hidden dims            │ 384     │
│ Dims with outliers     │ 2       │
│ Top 2 share            │ 100.00% │
│ Outlier dims (first 2) │ 264, 58 │
└────────────────────────┴─────────┘
                       Top 2 Dimensions (attn_norm)                       
┏━━━━━━┳━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━┓
┃ Rank ┃ Dim ┃ Count     ┃ % of outliers ┃ Pos %   ┃ Neg %   ┃ One-sided ┃
┡━━━━━━╇━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━┩
│ 1    │ 264 │ 1,152,406 │ 54.97%        │ 0.00%   │ 100.00% │ yes       │
│ 2    │ 58  │ 944,210   │ 45.03%        │ 100.00% │ 0.00%   │ yes       │
└──────┴─────┴───────────┴───────────────┴─────────┴─────────┴───────────┘
     Layer Outlier Occurrences     
            (attn_norm)            
┏━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer ┃ Count   ┃ % of outliers ┃
┡━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ 0     │ 0       │ 0.00%         │
│ 1     │ 131,039 │ 6.25%         │
│ 2     │ 131,039 │ 6.25%         │
│ 3     │ 131,039 │ 6.25%         │
│ 4     │ 131,039 │ 6.25%         │
│ 5     │ 131,039 │ 6.25%         │
│ 6     │ 131,039 │ 6.25%         │
│ 7     │ 130,745 │ 6.24%         │
│ 8     │ 129,335 │ 6.17%         │
│ 9     │ 126,243 │ 6.02%         │
│ 10    │ 121,936 │ 5.82%         │
│ 11    │ 115,957 │ 5.53%         │
│ 12    │ 109,277 │ 5.21%         │
│ 13    │ 100,621 │ 4.80%         │
│ 14    │ 90,509  │ 4.32%         │
│ 15    │ 80,019  │ 3.82%         │
│ 16    │ 69,405  │ 3.31%         │
│ 17    │ 60,857  │ 2.90%         │
│ 18    │ 52,524  │ 2.51%         │
│ 19    │ 44,409  │ 2.12%         │
│ 20    │ 36,892  │ 1.76%         │
│ 21    │ 26,021  │ 1.24%         │
│ 22    │ 14,042  │ 0.67%         │
│ 23    │ 1,590   │ 0.08%         │
└───────┴─────────┴───────────────┘
 First-Layer Appearance (attn_norm) 
┏━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━┓
┃ Layer ┃ Count   ┃ % of locations ┃
┡━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━┩
│ 0     │ 0       │ 0.00%          │
│ 1     │ 131,039 │ 100.00%        │
│ 2     │ 0       │ 0.00%          │
│ 3     │ 0       │ 0.00%          │
│ 4     │ 0       │ 0.00%          │
│ 5     │ 0       │ 0.00%          │
│ 6     │ 0       │ 0.00%          │
│ 7     │ 0       │ 0.00%          │
│ 8     │ 0       │ 0.00%          │
│ 9     │ 0       │ 0.00%          │
│ 10    │ 0       │ 0.00%          │
│ 11    │ 0       │ 0.00%          │
│ 12    │ 0       │ 0.00%          │
│ 13    │ 0       │ 0.00%          │
│ 14    │ 0       │ 0.00%          │
│ 15    │ 0       │ 0.00%          │
│ 16    │ 0       │ 0.00%          │
│ 17    │ 0       │ 0.00%          │
│ 18    │ 0       │ 0.00%          │
│ 19    │ 0       │ 0.00%          │
│ 20    │ 0       │ 0.00%          │
│ 21    │ 0       │ 0.00%          │
│ 22    │ 0       │ 0.00%          │
│ 23    │ 0       │ 0.00%          │
└───────┴─────────┴────────────────┘
Token Position Outliers (attn_norm)
┏━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Token ┃ Count   ┃ % of outliers ┃
┡━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ 0     │ 176,301 │ 8.41%         │
│ 1     │ 143,376 │ 6.84%         │
│ 2     │ 126,922 │ 6.05%         │
│ 3     │ 134,834 │ 6.43%         │
│ 4     │ 142,105 │ 6.78%         │
│ 5     │ 141,039 │ 6.73%         │
│ 6     │ 106,541 │ 5.08%         │
│ 7     │ 112,568 │ 5.37%         │
│ 8     │ 128,976 │ 6.15%         │
│ 9     │ 106,432 │ 5.08%         │
│ 10    │ 126,484 │ 6.03%         │
│ 11    │ 126,382 │ 6.03%         │
│ 12    │ 134,892 │ 6.43%         │
│ 13    │ 112,526 │ 5.37%         │
│ 14    │ 125,646 │ 5.99%         │
│ 15    │ 151,592 │ 7.23%         │
└───────┴─────────┴───────────────┘
    Outlier Magnitudes    
       (attn_norm)        
┏━━━━━━━━━━━━━━┳━━━━━━━━━┓
┃ Metric       ┃ Value   ┃
┡━━━━━━━━━━━━━━╇━━━━━━━━━┩
│ Min          │ 6.0000  │
│ Q1 (25%)     │ 8.4799  │
│ Median (50%) │ 10.0362 │
│ Q3 (75%)     │ 11.5871 │
│ Max          │ 13.8036 │
└──────────────┴─────────┘
Loaded mlp_input shape=(4096, 24, 16, 384) dtype=torch.float32 elements=603,979,776 ~2,304.0 MiB
Computing IQR estimate
Computing outlier mask
Filtering by layer-fraction requirement
Summarizing by hidden dimension/layer/token
Summarizing sign distribution
Summarizing first-layer emergence
Summarizing outlier magnitudes
IQR sample 2,000,000 values (seed=0)
                   Activation Outliers (mlp_input)                   
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Metric                             ┃ Value                        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ Input                              │ activations_500k.safetensors │
│ Key                                │ mlp_input                    │
│ Threshold                          │ 6.0000                       │
│ Min layer fraction                 │ 25.00%                       │
│ Tensor shape                       │ (4096, 24, 16, 384)          │
│ Elements > threshold               │ 2,371,593                    │
│ Outlier occurrences                │ 2,160,455                    │
│ Outlier occurrence rate            │ 0.3577%                      │
│ Outlier locations                  │ 131,068                      │
│ Outlier location rate              │ 0.5208%                      │
│ Mean layer-hit fraction (outliers) │ 68.68%                       │
│ Q1 (25%)                           │ -0.4791                      │
│ Median (50%)                       │ -0.0053                      │
│ Q3 (75%)                           │ 0.4672                       │
│ IQR (Q3-Q1)                        │ 0.9462                       │
└────────────────────────────────────┴──────────────────────────────┘
   Outlier Dimensions (mlp_input)   
┏━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┓
┃ Metric                 ┃ Value   ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━┩
│ Hidden dims            │ 384     │
│ Dims with outliers     │ 2       │
│ Top 2 share            │ 100.00% │
│ Outlier dims (first 2) │ 264, 58 │
└────────────────────────┴─────────┘
                       Top 2 Dimensions (mlp_input)                       
┏━━━━━━┳━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━┓
┃ Rank ┃ Dim ┃ Count     ┃ % of outliers ┃ Pos %   ┃ Neg %   ┃ One-sided ┃
┡━━━━━━╇━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━┩
│ 1    │ 264 │ 1,184,625 │ 54.83%        │ 0.00%   │ 100.00% │ yes       │
│ 2    │ 58  │ 975,830   │ 45.17%        │ 100.00% │ 0.00%   │ yes       │
└──────┴─────┴───────────┴───────────────┴─────────┴─────────┴───────────┘
     Layer Outlier Occurrences     
            (mlp_input)            
┏━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer ┃ Count   ┃ % of outliers ┃
┡━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ 0     │ 131,068 │ 6.07%         │
│ 1     │ 131,068 │ 6.07%         │
│ 2     │ 131,068 │ 6.07%         │
│ 3     │ 131,068 │ 6.07%         │
│ 4     │ 131,068 │ 6.07%         │
│ 5     │ 131,068 │ 6.07%         │
│ 6     │ 130,979 │ 6.06%         │
│ 7     │ 130,316 │ 6.03%         │
│ 8     │ 128,230 │ 5.94%         │
│ 9     │ 124,584 │ 5.77%         │
│ 10    │ 119,173 │ 5.52%         │
│ 11    │ 112,992 │ 5.23%         │
│ 12    │ 105,284 │ 4.87%         │
│ 13    │ 95,564  │ 4.42%         │
│ 14    │ 84,779  │ 3.92%         │
│ 15    │ 74,168  │ 3.43%         │
│ 16    │ 64,755  │ 3.00%         │
│ 17    │ 56,193  │ 2.60%         │
│ 18    │ 47,560  │ 2.20%         │
│ 19    │ 40,517  │ 1.88%         │
│ 20    │ 30,737  │ 1.42%         │
│ 21    │ 19,856  │ 0.92%         │
│ 22    │ 8,204   │ 0.38%         │
│ 23    │ 156     │ 0.01%         │
└───────┴─────────┴───────────────┘
 First-Layer Appearance (mlp_input) 
┏━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━┓
┃ Layer ┃ Count   ┃ % of locations ┃
┡━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━┩
│ 0     │ 131,068 │ 100.00%        │
│ 1     │ 0       │ 0.00%          │
│ 2     │ 0       │ 0.00%          │
│ 3     │ 0       │ 0.00%          │
│ 4     │ 0       │ 0.00%          │
│ 5     │ 0       │ 0.00%          │
│ 6     │ 0       │ 0.00%          │
│ 7     │ 0       │ 0.00%          │
│ 8     │ 0       │ 0.00%          │
│ 9     │ 0       │ 0.00%          │
│ 10    │ 0       │ 0.00%          │
│ 11    │ 0       │ 0.00%          │
│ 12    │ 0       │ 0.00%          │
│ 13    │ 0       │ 0.00%          │
│ 14    │ 0       │ 0.00%          │
│ 15    │ 0       │ 0.00%          │
│ 16    │ 0       │ 0.00%          │
│ 17    │ 0       │ 0.00%          │
│ 18    │ 0       │ 0.00%          │
│ 19    │ 0       │ 0.00%          │
│ 20    │ 0       │ 0.00%          │
│ 21    │ 0       │ 0.00%          │
│ 22    │ 0       │ 0.00%          │
│ 23    │ 0       │ 0.00%          │
└───────┴─────────┴────────────────┘
Token Position Outliers (mlp_input)
┏━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Token ┃ Count   ┃ % of outliers ┃
┡━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ 0     │ 180,962 │ 8.38%         │
│ 1     │ 147,287 │ 6.82%         │
│ 2     │ 131,076 │ 6.07%         │
│ 3     │ 138,369 │ 6.40%         │
│ 4     │ 146,105 │ 6.76%         │
│ 5     │ 145,261 │ 6.72%         │
│ 6     │ 110,695 │ 5.12%         │
│ 7     │ 116,585 │ 5.40%         │
│ 8     │ 133,034 │ 6.16%         │
│ 9     │ 110,665 │ 5.12%         │
│ 10    │ 130,226 │ 6.03%         │
│ 11    │ 130,134 │ 6.02%         │
│ 12    │ 138,530 │ 6.41%         │
│ 13    │ 116,580 │ 5.40%         │
│ 14    │ 129,408 │ 5.99%         │
│ 15    │ 155,538 │ 7.20%         │
└───────┴─────────┴───────────────┘
    Outlier Magnitudes    
       (mlp_input)        
┏━━━━━━━━━━━━━━┳━━━━━━━━━┓
┃ Metric       ┃ Value   ┃
┡━━━━━━━━━━━━━━╇━━━━━━━━━┩
│ Min          │ 6.0000  │
│ Q1 (25%)     │ 8.3261  │
│ Median (50%) │ 10.1242 │
│ Q3 (75%)     │ 11.5030 │
│ Max          │ 13.7897 │
└──────────────┴─────────┘
            Key Comparison            
┏━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┓
┃ Metric                 ┃ Value     ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━┩
│ Key A                  │ attn_norm │
│ Key B                  │ mlp_input │
│ Dims with outliers (A) │ 2         │
│ Dims with outliers (B) │ 2         │
│ Common dims            │ 2         │
│ Jaccard (dims)         │ 100.00%   │
└────────────────────────┴───────────┘
 Top Common Outlier Dims  
       (min count)        
┏━━━━━━┳━━━━━┳━━━━━━━━━━━┓
┃ Rank ┃ Dim ┃ Min count ┃
┡━━━━━━╇━━━━━╇━━━━━━━━━━━┩
│ 1    │ 264 │ 1,152,406 │
│ 2    │ 58  │ 944,210   │
└──────┴─────┴───────────┘
